import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import os

# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã®ãŸã‚ã«.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

def get_llm_response(user_question, expert_choice, api_key):
    
    system_message = "" # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆæœŸåŒ–
    if expert_choice == "ITã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        system_message = "ã‚ãªãŸã¯å„ªç§€ãªITã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚å°‚é–€ç”¨èªã‚’é¿ã‘ã€åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"
    elif expert_choice == "æ‹æ„›ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼":
        system_message = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ‹æ„›ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚è¦ªèº«ã«ã€ãã—ã¦å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚"
    elif expert_choice == "ã‚·ã‚§ãƒ•":
        system_message = "ã‚ãªãŸã¯ä¸€æµã®ã‚·ã‚§ãƒ•ã§ã™ã€‚å®¶åº­ã§ã‚‚ä½œã‚Œã‚‹ç°¡å˜ãªãƒ¬ã‚·ãƒ”ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    
    # ChatOpenAIã®åˆæœŸåŒ–æ™‚ã«ã€å—ã‘å–ã£ãŸAPIã‚­ãƒ¼ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
    llm = ChatOpenAI(
        api_key=api_key, 
        model_name="gpt-4o-mini", 
        temperature=0.7
    )
    
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=user_question),
    ]
    
    try:
        result = llm.invoke(messages)
        return result.content
    except Exception as e:
        st.error(f"LLMã‹ã‚‰ã®å›ç­”å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# --- Streamlitã‚¢ãƒ—ãƒªã®ç”»é¢ ---

st.title("å°‚é–€å®¶AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write("å°‚é–€å®¶ã‚’é¸æŠã—ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
st.divider()

# --- APIã‚­ãƒ¼ã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ ---
# ã¾ãšã€Streamlit Cloudã®Secretsã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    key_source = "Streamlit Secrets"
# SecretsãŒãªã‘ã‚Œã°ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ç’°å¢ƒå¤‰æ•°ï¼ˆ.envã‹ã‚‰èª­ã¿è¾¼ã¾ã‚ŒãŸã‚‚ã®ï¼‰ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
except (KeyError, FileNotFoundError):
    api_key = os.getenv("OPENAI_API_KEY")
    key_source = "ãƒ­ãƒ¼ã‚«ãƒ«ã® .env ãƒ•ã‚¡ã‚¤ãƒ«"

# --- UIã®è¡¨ç¤º ---
if api_key:
    # st.success(f"APIã‚­ãƒ¼ã‚’ã€Œ{key_source}ã€ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚") # ãƒ‡ãƒãƒƒã‚°ç”¨
    
    expert_choice = st.radio(
        "ã©ã®å°‚é–€å®¶ã«ç›¸è«‡ã—ã¾ã™ã‹ï¼Ÿ",
        ("ITã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ", "æ‹æ„›ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "ã‚·ã‚§ãƒ•")
    )
    user_question = st.text_area("ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    if st.button("AIã«ç›¸è«‡ã™ã‚‹"):
        st.divider()
        if user_question:
            with st.spinner("AIãŒå›ç­”ã‚’è€ƒãˆã¦ã„ã¾ã™..."):
                response = get_llm_response(user_question, expert_choice, api_key)
            
            if response:
                st.subheader("ğŸ¤– AIã‹ã‚‰ã®å›ç­”")
                st.markdown(response)
        else:
            st.error("ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
else:
    st.error("ã‚¨ãƒ©ãƒ¼: OpenAIã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info("ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã®å ´åˆã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã€Streamlit Cloudã®å ´åˆã¯Secretsã«APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")